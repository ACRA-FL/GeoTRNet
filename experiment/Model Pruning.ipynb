{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Experiment Details\n",
    "__Experiment Id__ : 006 \\\n",
    "__Target__ : Test the model performance on the hand-written razor images \\\n",
    "__Solution__ : \n",
    "- create MNIST sticker set\n",
    "- train and test model on mnist dataset\n",
    "\n",
    "__Empirical result__ : \n",
    "- model size be even smaller [9574]\n",
    "- get to very high accuracy\n",
    "- shows clean outputs in the inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from skimage import io, transform \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from tcn import TCN\n",
    "\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128,48)\n",
    "DATA_BS = 10\n",
    "DATA_N = 10\n",
    "LR = 0.005\n",
    "EPOCHS = 10\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dataset & Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load dataset info from ~\\tensorflow_datasets\\mnist\\3.0.1\n",
      "Reusing dataset mnist (~\\tensorflow_datasets\\mnist\\3.0.1)\n",
      "Constructing tf.data.Dataset mnist for split ['train', 'test'], from ~\\tensorflow_datasets\\mnist\\3.0.1\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), info = tfds.load('mnist', split=['train', 'test'], with_info=True)\n",
    "train_gen = tfds.as_numpy(ds_train)\n",
    "test_gen = tfds.as_numpy(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(object):\n",
    "\n",
    "    def __init__(self, n_digits=8, image_size=(156, 32)):\n",
    "        self.n_digits = n_digits\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def gen_data(self, gen):\n",
    "        images, labels = [], []\n",
    "        for x in gen:\n",
    "            images.append(x['image'])\n",
    "            labels.append(x['label'])\n",
    "        images, labels = np.squeeze(np.array(images)), np.squeeze(np.array(labels)); print(images.shape,labels.shape,labels)\n",
    "        return images, labels\n",
    "\n",
    "    def gen_patch(self, img, ann, c=np.inf):\n",
    "        size = img.shape[0]\n",
    "        indexes = np.arange(size)\n",
    "        np.random.shuffle(indexes)\n",
    "        \n",
    "        c_prime = divmod(size, self.n_digits)[0]*self.n_digits\n",
    "        if c_prime < c:\n",
    "            size = c_prime\n",
    "        else:\n",
    "            size = divmod(c, self.n_digits)[0]*self.n_digits\n",
    "\n",
    "        sample_index = indexes[:size]\n",
    "        sticker_index = sample_index.reshape((-1, self.n_digits)).T\n",
    "        sticker_images = np.transpose(np.hstack([np.transpose(img[inds], (0, 2, 1)) for inds in sticker_index]), (0, 2, 1))\n",
    "        sfl_label =  ann[sample_index, ...]\n",
    "        sticker_labels = sfl_label.reshape((-1, self.n_digits))\n",
    "        return sticker_images, sticker_labels\n",
    "\n",
    "    def generate(self, data_generator, n_sample):\n",
    "        init_image, init_label = self.gen_data(data_generator)\n",
    "        c = n_sample\n",
    "        dt_images, dt_labels = self.gen_patch(init_image, init_label, c)\n",
    "        while c > self.n_digits:\n",
    "            c = n_sample - dt_images.shape[0]\n",
    "            p_images, p_labels = self.gen_patch(init_image, init_label, c)\n",
    "            dt_images, dt_labels = np.vstack((dt_images, p_images)), np.vstack((dt_labels, p_labels))\n",
    "\n",
    "        ret_tensor = tf.convert_to_tensor(np.swapaxes(dt_images, 1, 2), dtype=tf.float32);print(dt_images.shape,dt_labels.shape)\n",
    "        ind_tensor = tf.convert_to_tensor(dt_labels, dtype=tf.int32)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((ret_tensor, ind_tensor))\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNISTDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) [4 1 0 ... 6 1 5]\n",
      "(9993, 28, 224) (9993, 8)\n",
      "(10000, 28, 28) (10000,) [2 0 4 ... 8 0 5]\n",
      "(1993, 28, 224) (1993, 8)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = mnist.generate(train_gen, n_sample=10000)\n",
    "test_dataset = mnist.generate(test_gen, n_sample=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 28)\n",
      "[4 6 8 7 8 3 7 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in test_dataset.take(1):\n",
    "    img, label = i\n",
    "print(img.shape)\n",
    "print(label.numpy())\n",
    "plt.imshow(img.numpy().T)\n",
    "IMAGE_SIZE = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_dataset.shuffle(buffer_size=1000).batch(BS, drop_remainder=True).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_loader = test_dataset.batch(BS, drop_remainder=True).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Model Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecNet(tf.keras.Model):\n",
    "\tdef __init__(self, bs=16, input_size=(128, 48), n_classes=10, h_cell=64, max_obj=15, linear_k=3, latent_size=32, rho=0.05):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.bs = bs\n",
    "\t\tself.rho = rho\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.n_classes = n_classes  # LSTM module projection size\n",
    "\t\tself.h_cell = h_cell  # LSTM hidden size\n",
    "\t\tself.max_obj = max_obj\n",
    "\t\tself.linear_k = linear_k\n",
    "\t\tself.latent_size = latent_size\n",
    "\t\tself.model = self.build_model(\n",
    "\t\t\tself.input_size, self.h_cell, self.n_classes, self.max_obj, self.latent_size, self.linear_k)\n",
    "\n",
    "\t\tself.scce = losses.SparseCategoricalCrossentropy(from_logits=False,)\n",
    "\n",
    "\t\tself.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\t\tself.acc_metric = tf.keras.metrics.Mean(name=\"accuracy\")\n",
    "\t\tself.acc_mat = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "\tdef build_model(self, input_shape=(128, 48), h_cell=32, n_classes=10, n_obj=10, latent_size=32, linear_k=3):\n",
    "\t\tforward_layer = layers.LSTM(h_cell//2, return_sequences=True)\n",
    "\t\tmodel = tf.keras.Sequential([\n",
    "\t\t\tlayers.Input(shape=input_shape, name='input_layer'),\n",
    "\t\t\tlayers.LSTM(latent_size, activation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=True, go_backwards=True),\n",
    "\t\t\tlayers.Conv1D(n_classes, linear_k, activation='tanh', name='projection_encoder'),\n",
    "\t\t\tlayers.Permute((2, 1)),\n",
    "\t\t\tlayers.Conv1D(n_obj, 1, activation='tanh'),\n",
    "\t\t\tlayers.Permute((2, 1)),\n",
    "\t\t\tlayers.Activation('softmax')\n",
    "\t\t])\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "\t@property\n",
    "\tdef metrics(self):\n",
    "\t\treturn [self.loss_metric, self.acc_mat]\n",
    "\n",
    "\tdef calculate_loss(self, target, pred):\n",
    "\t\ttarget = tf.reshape(target, shape=(-1))\n",
    "\t\tpred = tf.reshape(pred, shape=(-1, self.n_classes))\n",
    "\t\tloss = self.scce(target, pred)\n",
    "\n",
    "\t\ty_hat = tf.argmax(pred, axis=-1)\n",
    "\t\tacc = self.acc_mat(y_hat, target)\n",
    "\t\treturn loss, acc\n",
    "\n",
    "\tdef call(self, x):\n",
    "\t\tfull_out = self.model(x)\n",
    "\t\treturn full_out\n",
    "\n",
    "\tdef train_step(self, batch_data):\n",
    "\t\tx, target = batch_data\n",
    "\t\te_ws = []\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tpred = self(x, training=True)\n",
    "\t\t\t# print(pred.shape, pred)\n",
    "\t\t\tloss, acc = self.calculate_loss(target, pred)\n",
    "\n",
    "\t\ttrainable_params = self.trainable_variables\n",
    "\t\tgradients = tape.gradient(loss, trainable_params)\n",
    "\t\tgrad_norm = self._grad_norm(gradients)\n",
    "\t\tscale = self.rho / (grad_norm + 1e-12)\n",
    "\n",
    "\t\tfor (grad, param) in zip(gradients, trainable_params):\n",
    "\t\t\te_w = grad*scale \n",
    "\t\t\tparam.assign_add(e_w)\n",
    "\t\t\te_ws.append(e_w)\n",
    "\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tpred = self(x, training=True)\n",
    "\t\t\tloss, acc = self.calculate_loss(target, pred)\n",
    "\n",
    "\t\tsam_gradient = tape.gradient(loss, trainable_params)\n",
    "\t\tfor (param, e_w) in zip(trainable_params, e_ws):\n",
    "\t\t\tparam.assign_sub(e_w)\n",
    "\n",
    "\t\tself.optimizer.apply_gradients(zip(sam_gradient, trainable_params))\n",
    "\t\tself.loss_metric.update_state(loss)\n",
    "\t\tself.acc_metric.update_state(acc)\n",
    "\t\treturn {\n",
    "\t\t\t\"loss\": self.loss_metric.result(),\n",
    "\t\t\t\"accuracy\": self.acc_mat.result(),\n",
    "\t\t}\n",
    "\n",
    "\tdef test_step(self, batch_data):\n",
    "\t\tx, target = batch_data\n",
    "\n",
    "\t\tpred = self(x, training=False)\n",
    "\t\tloss, acc = self.calculate_loss(target, pred)\n",
    "\n",
    "\t\tself.loss_metric.update_state(loss)\n",
    "\t\tself.acc_metric.update_state(acc)\n",
    "\t\treturn {\n",
    "\t\t\t\"loss\": self.loss_metric.result(),\n",
    "\t\t\t\"accuracy\": self.acc_mat.result(),\n",
    "\t\t}\n",
    "\n",
    "\tdef _grad_norm(self, gradients):\n",
    "\t\tnorm = tf.norm(\n",
    "\t\t\ttf.stack([\n",
    "\t\t\t\ttf.norm(grad) for grad in gradients if grad is not None\n",
    "\t\t\t])\n",
    "\t\t)\n",
    "\t\treturn norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "recNet = RecNet(input_size=IMAGE_SIZE,\n",
    "                bs=BS,\n",
    "                n_classes=10,\n",
    "                h_cell=64,\n",
    "                max_obj=8,\n",
    "                linear_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 224, 32)           7808      \n",
      "                                                                 \n",
      " projection_encoder (Conv1D)  (None, 222, 10)          970       \n",
      "                                                                 \n",
      " permute_4 (Permute)         (None, 10, 222)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 10, 8)             1784      \n",
      "                                                                 \n",
      " permute_5 (Permute)         (None, 8, 10)             0         \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 10)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,562\n",
      "Trainable params: 10,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recNet.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Set up model training details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_time_based_decay(epoch, lr):\n",
    "    decay = 0.001\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    return LR * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "\n",
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.1\n",
    "    return LR * math.exp(-k*epoch)\n",
    "\n",
    "decay_steps = 1000\n",
    "# lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     LR, decay_steps)\n",
    "\n",
    "lr_decaying_callback = tf.keras.callbacks.LearningRateScheduler(lr_step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                            monitor='val_accuracy',\n",
    "                            min_delta=0,\n",
    "                            patience=2,\n",
    "                            restore_best_weights=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RecNet(bs=BS)\n",
    "model = RecNet(input_size=IMAGE_SIZE,\n",
    "                bs=BS,\n",
    "                n_classes=10,\n",
    "                h_cell=64,\n",
    "                max_obj=8,\n",
    "                linear_k=3)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.wrappers.Bidirectional at 0x1fb51b30100>,\n",
       " <keras.layers.recurrent_v2.LSTM at 0x1fb51b1fa00>,\n",
       " <keras.layers.convolutional.Conv1D at 0x1fb51b2b250>,\n",
       " <keras.layers.core.permute.Permute at 0x1fb51b30f10>,\n",
       " <keras.layers.convolutional.Conv1D at 0x1fb51b37fd0>,\n",
       " <keras.layers.core.permute.Permute at 0x1fb51b2b640>,\n",
       " <keras.layers.core.activation.Activation at 0x1fb51b37970>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 49s 127ms/step - loss: 1.1171 - accuracy: 0.8318 - val_loss: 0.8984 - val_accuracy: 0.9439 - lr: 0.0050\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 0.9101 - accuracy: 0.9421 - val_loss: 0.8866 - val_accuracy: 0.9490 - lr: 0.0050\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 46s 147ms/step - loss: 0.8935 - accuracy: 0.9497 - val_loss: 0.8766 - val_accuracy: 0.9536 - lr: 0.0050\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 0.8838 - accuracy: 0.9547 - val_loss: 0.8697 - val_accuracy: 0.9557 - lr: 0.0050\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 0.8751 - accuracy: 0.9596 - val_loss: 0.8627 - val_accuracy: 0.9604 - lr: 0.0050\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 46s 146ms/step - loss: 0.8797 - accuracy: 0.9569 - val_loss: 0.8638 - val_accuracy: 0.9606 - lr: 0.0050\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 48s 155ms/step - loss: 0.8722 - accuracy: 0.9601 - val_loss: 0.8599 - val_accuracy: 0.9609 - lr: 0.0050\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 0.8720 - accuracy: 0.9598 - val_loss: 0.8643 - val_accuracy: 0.9626 - lr: 0.0050\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 42s 135ms/step - loss: 0.8700 - accuracy: 0.9616 - val_loss: 0.8621 - val_accuracy: 0.9608 - lr: 0.0050\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 43s 137ms/step - loss: 0.8666 - accuracy: 0.9630 - val_loss: 0.8603 - val_accuracy: 0.9652 - lr: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb51b237c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_loader,\n",
    "    callbacks=[earlystopping_callback,\n",
    "               lr_decaying_callback]\n",
    ")\n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model before pruning\n",
    "model.save_weights('../../tmp/models/sample_mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Model pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=5)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model.model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/312 [..............................] - ETA: 20s - loss: 0.9053 - accuracy: 0.9398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_end` time: 0.0492s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 17s 40ms/step - loss: 0.8800 - accuracy: 0.9534 - val_loss: 0.8858 - val_accuracy: 0.9513\n",
      "Epoch 2/2\n",
      "312/312 [==============================] - 10s 31ms/step - loss: 0.8716 - accuracy: 0.9578 - val_loss: 0.8841 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d055e2f10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='logs'),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(\n",
    "    train_loader,\n",
    "    epochs=2,\n",
    "    validation_data=valid_loader,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.save_weights('../../tmp/models/pruned_sample_mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Comparison between pruned and original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model file size : 133289 \n",
      " pruned model file size : 177329 \n",
      " model shrinkage percentage : -0.3304098612788752%\n"
     ]
    }
   ],
   "source": [
    "orig_model_size = os.path.getsize('../../tmp/models/sample_mnist.ckpt.data-00000-of-00001') + os.path.getsize('../../tmp/models/sample_mnist.ckpt.index')\n",
    "pruned_model_size = os.path.getsize('../../tmp/models/pruned_sample_mnist.ckpt.data-00000-of-00001') + os.path.getsize('../../tmp/models/pruned_sample_mnist.ckpt.index')\n",
    "prec = (orig_model_size-pruned_model_size)/orig_model_size\n",
    "print(f' original model file size : {orig_model_size} \\n pruned model file size : {pruned_model_size} \\n model shrinkage percentage : {prec}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000,) [2 0 4 ... 8 0 5]\n",
      "(1993, 28, 224) (1993, 8)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = mnist.generate(test_gen, n_sample=2000)\n",
    "test_loader = test_dataset.batch(BS, drop_remainder=True).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 21ms/step - loss: 0.8858 - accuracy: 0.9527\n"
     ]
    }
   ],
   "source": [
    "k = model.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8858 - accuracy: 0.9527\n"
     ]
    }
   ],
   "source": [
    "k1 = model_for_pruning.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t\t loss \t\t\t accuracy\n",
      "original model > 0.8857819437980652 0.9526839852333069 \n",
      "pruned model   > 0.8857819437980652 0.9526839852333069\n"
     ]
    }
   ],
   "source": [
    "print(f\" \\t\\t loss \\t\\t\\t accuracy\\noriginal model > {k[0]} {k[1]} \\npruned model   > {k1[0]} {k1[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view pruning logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45968), started 0:04:39 ago. (Use '!kill 45968' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-caed1ebe77668802\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-caed1ebe77668802\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={'logs'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08aea5f70877f29c16b88dd2c4446bb1b0b98820cbf110aea5656aecf55fbfb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
